{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "import pandas as pd\n",
    "from datenverarbeitung.dataloader import dataloader\n",
    "from IPython.display import clear_output\n",
    "import datetime\n",
    "\n",
    "\n",
    "num_scenario = 3\n",
    "nr_taps = 1\n",
    "learning_cycles = 25\n",
    "features_to_learn_with = [\"pitch\",\"nosetip_y\",\"nosetip_x\",\"chin_x\",\"chin_y\",\"roll\",\"yaw\",\"left_eye_corner_x\",\"left_eye_corner_y\",\"right_eye_corner_x\",\"right_eye_corner_y\",\"left_mouth_corner_x\",\"left_mouth_corner_y\",\"right_mouth_corner_x\",\"right_mouth_corner_y\",\"nose_end_point_x\",\"nose_end_point_y\",\"head_pose1_x\",\"head_pose1_y\",\"head_pose2_x\",\"head_pose2_y\"]\n",
    "feature_list_string = '_'.join(features_to_learn_with)\n",
    "models_folder = \"models\"\n",
    "plots_folder = \"vis/plots\"\n",
    "\n",
    "dl = dataloader(scenario= num_scenario, path=\"/Users/adi/Nextcloud/smart_hans/AP2/Daten/headpose_opencv_pitch_roll_yaw_20220904\", nr_taps=nr_taps, move_window_by=-10, feature_list=features_to_learn_with)\n",
    "df_n = dl.df\n",
    "\n",
    "cols = list(df_n.columns)\n",
    "a, b = cols.index('sample_index'), cols.index('feature')\n",
    "cols[b], cols[a] = cols[a], cols[b]\n",
    "df_n = df_n[cols]\n",
    "print(df_n)\n",
    "df_n = df_n.sort_values(['feature','target'])#.reset_index(drop=True)\n",
    "\n",
    "print(df_n[\"feature\"])\n",
    "print(df_n['sample_index'])\n",
    "print(\" hhhhhhhh \")\n",
    "\n",
    "X, old_y, names = df2xy (df_n, sample_col='sample_index', feat_col='feature', target_col='target', data_cols=None, steps_in_rows=True, return_names=True)\n",
    "\n",
    "print(names)\n",
    "print(f\"shape ours {df_n.shape}\")\n",
    "\n",
    "print(\"our X\")\n",
    "print(X.shape)\n",
    "print(X)\n",
    "\n",
    "print(\"our y\")\n",
    "print(old_y)\n",
    "print(old_y.shape)\n",
    "\n",
    "y = np.empty(len(old_y))\n",
    "for i, elem in enumerate(old_y):\n",
    "            remainder = int(elem[0]) % 10\n",
    "            y[i] = remainder\n",
    "print(y)\n",
    "print(y.shape)\n",
    "   \n",
    "splits = get_splits(y, valid_size=.2)\n",
    "\n",
    "tfms  = [None, TSRegression()]\n",
    "\n",
    "dsets = TSDatasets( X,y,  inplace=True, splits=splits, tfms=[None, TSClassification()])\n",
    "\n",
    "print(dsets)\n",
    "\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, num_workers=0, tfms=[None, TSClassification()], item_tfs=TSClassification())\n",
    "\n",
    "dls.show_batch(sharey=True)\n",
    "\n",
    "archs = [(FCN, {}), (ResNet, {}), (xresnet1d34, {}), (ResCNN, {}), \n",
    "        (LSTM, {'n_layers':1, 'bidirectional': False}), (LSTM, {'n_layers':2, 'bidirectional': False}), (LSTM, {'n_layers':3, 'bidirectional': False}), \n",
    "        (LSTM, {'n_layers':1, 'bidirectional': True}), (LSTM, {'n_layers':2, 'bidirectional': True}), (LSTM, {'n_layers':3, 'bidirectional': True}),\n",
    "        (LSTM_FCN, {}), (LSTM_FCN, {'shuffle': False}), (InceptionTime, {}), (XceptionTime, {}), (OmniScaleCNN, {}), (mWDN, {'levels': 4})]\n",
    "\n",
    "results = pd.DataFrame(columns=['arch', 'hyperparams',  'train loss', 'valid loss', 'accuracy', 'time'])\n",
    "for i, (arch, k) in enumerate(archs):\n",
    "\n",
    "    save_name = \"multivariate_scenario_{}_{}_features_{}\".format(num_scenario, arch.__name__,\"features_\"+str(len(features_to_learn_with)))\n",
    "    ## set parameters for modelsaves\n",
    "    scenario_name_stage0 = save_name+\"_nr_taps_{}\".format(str(nr_taps))+\"_stage0\"\n",
    "\n",
    "    model = create_model(arch, dls=dls, **k)\n",
    "    print(model.__class__.__name__)\n",
    "    learn = Learner(dls, model,  metrics=accuracy)\n",
    "\n",
    "    learn.save(scenario_name_stage0)\n",
    "    learn.load(scenario_name_stage0)\n",
    "    learn.lr_find()\n",
    "    scenario_name_stage1 = scenario_name_stage0.replace(\"0\",\"1\")\n",
    "\n",
    "    start = time.time()\n",
    "    learn.fit_one_cycle(learning_cycles, 1e-3)\n",
    "    elapsed = time.time() - start\n",
    "    vals = learn.recorder.values[-1]\n",
    "    results.loc[i] = [arch.__name__, k, vals[0], vals[1], vals[2], int(elapsed)]\n",
    "    results.sort_values(by='accuracy', ascending=False, ignore_index=True, inplace=True)\n",
    "    \n",
    "    learn.plot_confusion_matrix()\n",
    "    current_time= datetime.datetime.now().strftime('%d%m%Y_%H%M%S')\n",
    "    plot_name = plots_folder+\"/confusion_matrix_\"+save_name+\"_nrtaps_{}_features_{}_learning_cycles_{}_{}.png\".format(str(nr_taps),str(len(features_to_learn_with)),learning_cycles, current_time)\n",
    "    plt.savefig(plot_name, ext='png', bbox_inches=\"tight\")\n",
    "    clear_output(wait=True)\n",
    "    display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_sizes = [10,20,30,40,50,60,70,80]\n",
    "movers = [40,35,30,25,20,15,10,5]\n",
    "all_features = [\"nosetip_x\",\"nosetip_y\",\"chin_x\",\"chin_y\",\"left_eye_corner_x\",\"left_eye_corner_y\",\"right_eye_corner_x\",\"right_eye_corner_y\",\"left_mouth_corner_x\",\"left_mouth_corner_y\",\"right_mouth_corner_x\",\"right_mouth_corner_y\",\"nose_end_point_x\",\"nose_end_point_y\",\"head_pose1_x\",\"head_pose1_y\",\"head_pose2_x\",\"head_pose2_y\", \"pitch\",\"roll\",\"yaw\"]\n",
    "features_to_learn_with = []\n",
    "counter = 0 \n",
    "for i in range(0,len(all_features),2):\n",
    "    if (i<len(all_features)-2):\n",
    "        features_to_learn_with.append(all_features[i])\n",
    "        features_to_learn_with.append(all_features[i+1])\n",
    "    else :\n",
    "        features_to_learn_with.append(all_features[i])\n",
    "    for tap_size in tap_sizes:\n",
    "        for move_by in movers:\n",
    "            \n",
    "            counter += 1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "import pandas as pd\n",
    "from datenverarbeitung.dataloader import dataloader\n",
    "from IPython.display import clear_output\n",
    "import datetime\n",
    "\n",
    "num_scenario = 3\n",
    "nr_taps = 1\n",
    "tap_sizes = [10,20,30,40,50,60,70,80]\n",
    "movers = [40,35,30,25,20,15,10,5]\n",
    "all_features = [\"nosetip_x\",\"nosetip_y\",\"chin_x\",\"chin_y\",\"left_eye_corner_x\",\"left_eye_corner_y\",\"right_eye_corner_x\",\"right_eye_corner_y\",\"left_mouth_corner_x\",\"left_mouth_corner_y\",\"right_mouth_corner_x\",\"right_mouth_corner_y\",\"nose_end_point_x\",\"nose_end_point_y\",\"head_pose1_x\",\"head_pose1_y\",\"head_pose2_x\",\"head_pose2_y\", \"pitch\",\"roll\",\"yaw\"]\n",
    "features_to_learn_with = []\n",
    "learning_cycles = 10\n",
    "feature_list_string = '_'.join(features_to_learn_with)\n",
    "models_folder = \"models/compare_multivariate\"\n",
    "plots_folder = \"vis/plots/compare_multivariate\"\n",
    "\n",
    "for i in range(0,len(all_features),2):\n",
    "    if (i<len(all_features)-2):\n",
    "        features_to_learn_with.append(all_features[i])\n",
    "        features_to_learn_with.append(all_features[i+1])\n",
    "    else :\n",
    "        features_to_learn_with.append(all_features[i])\n",
    "    for tap_size in tap_sizes:\n",
    "        for move_by in movers:\n",
    "            dl = dataloader(scenario= num_scenario, path=\"/Users/adi/Nextcloud/smart_hans/AP2/Daten/headpose_opencv_pitch_roll_yaw_20220904\", nr_taps=nr_taps, move_window_by=move_by, tap_size=tap_size, feature_list=features_to_learn_with)\n",
    "            df_n = dl.df\n",
    "\n",
    "            cols = list(df_n.columns)\n",
    "            a, b = cols.index('sample_index'), cols.index('feature')\n",
    "            cols[b], cols[a] = cols[a], cols[b]\n",
    "            df_n = df_n[cols]\n",
    "            df_n = df_n.sort_values(['feature','target'])#.reset_index(drop=True)\n",
    "\n",
    "            X, old_y, names = df2xy (df_n, sample_col='sample_index', feat_col='feature', target_col='target', data_cols=None, steps_in_rows=True, return_names=True)\n",
    "\n",
    "            y = np.empty(len(old_y))\n",
    "            for i, elem in enumerate(old_y):\n",
    "                        remainder = int(elem[0]) % 10\n",
    "                        y[i] = remainder\n",
    "            \n",
    "            splits = get_splits(y, valid_size=.2)\n",
    "\n",
    "            tfms  = [None, TSRegression()]\n",
    "\n",
    "            dsets = TSDatasets( X,y,  inplace=True, splits=splits, tfms=[None, TSClassification()])\n",
    "            dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, num_workers=0, tfms=[None, TSClassification()], item_tfs=TSClassification())\n",
    "\n",
    "            dls.show_batch(sharey=True)\n",
    "\n",
    "            archs = [(FCN, {}), (ResNet, {}), (xresnet1d34, {}), (ResCNN, {}), \n",
    "                    (LSTM, {'n_layers':1, 'bidirectional': False}), (LSTM, {'n_layers':2, 'bidirectional': False}), (LSTM, {'n_layers':3, 'bidirectional': False}), \n",
    "                    (LSTM, {'n_layers':1, 'bidirectional': True}), (LSTM, {'n_layers':2, 'bidirectional': True}), (LSTM, {'n_layers':3, 'bidirectional': True}),\n",
    "                    (LSTM_FCN, {}), (LSTM_FCN, {'shuffle': False}), (InceptionTime, {}), (XceptionTime, {}), (OmniScaleCNN, {})]\n",
    "\n",
    "            results = pd.DataFrame(columns=['arch', 'hyperparams',  'train loss', 'valid loss', 'accuracy', 'time'])\n",
    "            for i, (arch, k) in enumerate(archs):\n",
    "\n",
    "                save_name = \"multivariate_scenario_{}_{}_features_{}_tapsize_{}_mv_{}\".format(num_scenario, arch.__name__,str(len(features_to_learn_with)),tap_size, move_by)\n",
    "                ## set parameters for modelsaves\n",
    "                scenario_name_stage0 = save_name+\"_nr_taps_{}\".format(str(nr_taps))+\"_stage0\"\n",
    "\n",
    "                model = create_model(arch, dls=dls, **k)\n",
    "                print(model.__class__.__name__)\n",
    "                learn = Learner(dls, model,  metrics=accuracy)\n",
    "\n",
    "                learn.save(scenario_name_stage0)\n",
    "                learn.load(scenario_name_stage0)\n",
    "                learn.lr_find()\n",
    "                scenario_name_stage1 = scenario_name_stage0.replace(\"0\",\"1\")\n",
    "\n",
    "                start = time.time()\n",
    "                learn.fit_one_cycle(learning_cycles, 1e-3)\n",
    "                elapsed = time.time() - start\n",
    "                vals = learn.recorder.values[-1]\n",
    "                results.loc[i] = [arch.__name__, k, vals[0], vals[1], vals[2], int(elapsed)]\n",
    "                results.sort_values(by='accuracy', ascending=False, ignore_index=True, inplace=True)\n",
    "                \n",
    "                learn.plot_confusion_matrix()\n",
    "                current_time= datetime.datetime.now().strftime('%d%m%Y_%H%M%S')\n",
    "                plot_name = plots_folder+\"/confusion_matrix_\"+save_name+\"_nrtaps_{}_learning_cycles_{}_{}.png\".format(str(nr_taps),learning_cycles, current_time)\n",
    "                plt.savefig(plot_name, ext='png', bbox_inches=\"tight\")\n",
    "                clear_output(wait=True)\n",
    "                display(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('smart_hans')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "021b3e9f0c86e8922dab1bedac4ca68f2b510d0410cb33551fb465a3ad17da22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

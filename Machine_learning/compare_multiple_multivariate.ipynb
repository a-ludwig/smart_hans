{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart_hans_07312022_173453_4_131-155_08_mnn_.csv\n",
      "smart_hans_07312022_171736_10_271-296_08_mnn_.csv\n",
      "smart_hans_08022022_182936_5_185-215_08_wny_.csv\n",
      "smart_hans_08022022_211852_10_341-371_08_mky_.csv\n",
      "smart_hans_07312022_182331_4_149-180_08_wnn_.csv\n",
      "smart_hans_08022022_190740_9_301-331_08_mny_.csv\n",
      "smart_hans_07312022_181701_7_243-273_08_wny_.csv\n",
      "smart_hans_07252022_154619_12_431-469_08_mgy_.csv\n",
      "smart_hans_08022022_192941_6_217-247_08_wny_.csv\n",
      "smart_hans_07312022_173105_12_400-431_08_mnn_.csv\n",
      "smart_hans_07312022_175436_12_339-368_08_mny_.csv\n",
      "smart_hans_08022022_192131_8_280-310_08_wny_.csv\n",
      "smart_hans_07312022_161925_10_313-339_08_mny_.csv\n",
      "smart_hans_08022022_191248_9_307-336_08_mny_.csv\n",
      "smart_hans_08022022_192219_4_154-184_08_wny_person_hat_nach_12_gewackelt.csv\n",
      "smart_hans_08022022_174636_13_433-463_08_wyn_.csv\n",
      "smart_hans_07252022_154808_9_313-351_08_mny_.csv\n",
      "smart_hans_07312022_170216_4_149-178_08_mgy_furz_lachen_am_ende.csv\n",
      "smart_hans_08022022_195007_9_312-344_08_gny_.csv\n",
      "smart_hans_08022022_194923_10_343-374_08_gny_.csv\n",
      "smart_hans_08022022_192033_4_152-183_08_wny_.csv\n",
      "smart_hans_08022022_190823_13_429-460_08_mny_person_hat_nicht_auf_huf_geschaut.csv\n",
      "smart_hans_08022022_184235_9_301-330_08_mgy_.csv\n",
      "smart_hans_08022022_185606_9_309-339_08_mny_.csv\n",
      "smart_hans_08022022_174942_9_308-339_08_wny_.csv\n",
      "smart_hans_08022022_192424_3_121-152_08_wny_.csv\n",
      "smart_hans_07252022_153833_8_281-318_08_mgy_adrian_im_hintergrund.csv\n",
      "smart_hans_08022022_180327_3_121-151_08_wkn_.csv\n",
      "smart_hans_08022022_175032_6_213-243_08_wny_.csv\n",
      "smart_hans_07252022_155048_13_482-523_08_mny_.csv\n",
      "smart_hans_08022022_184912_11_368-398_08_mny_.csv\n",
      "smart_hans_08022022_184536_10_330-361_08_mgy_.csv\n",
      "smart_hans_08022022_175644_3_121-152_08_wkn_.csv\n",
      "smart_hans_08022022_174832_7_246-277_08_wny_.csv\n",
      "smart_hans_07312022_172617_3_114-140_08_mnn_.csv\n",
      "smart_hans_07312022_174435_8_248-279_08_mny_.csv\n",
      "smart_hans_08022022_182746_7_242-273_08_wny_.csv\n",
      "smart_hans_07312022_170052_6_215-244_08_mgy_.csv\n",
      "smart_hans_07312022_173830_8_277-307_08_mny_.csv\n",
      "smart_hans_07312022_171246_5_174-198_08_mnn_.csv\n",
      "smart_hans_08022022_184110_5_176-207_08_mgy_.csv\n",
      "smart_hans_07312022_184005_11_374-404_08_mny_.csv\n",
      "smart_hans_08022022_182519_4_150-180_08_wny_.csv\n",
      "smart_hans_08022022_190601_5_182-212_08_mny_.csv\n",
      "smart_hans_08022022_190359_6_212-241_08_mny_person_hat sich_weggedreht.csv\n",
      "smart_hans_08022022_211938_13_430-461_08_mky_.csv\n",
      "smart_hans_08022022_195222_3_123-154_08_gny_.csv\n",
      "smart_hans_08022022_194751_7_250-281_08_gny_.csv\n",
      "smart_hans_07252022_155230_11_402-439_08_mgy_.csv\n",
      "smart_hans_08022022_205037_4_154-186_08_wnn_.csv\n",
      "smart_hans_07312022_185028_13_339-362_08_wky_.csv\n",
      "smart_hans_08022022_182830_13_434-464_08_wny_.csv\n",
      "smart_hans_07312022_171557_13_347-371_08_mnn_.csv\n",
      "smart_hans_08022022_195403_4_153-183_08_gny_.csv\n",
      "smart_hans_08022022_204902_13_438-467_08_wny_gesicht nicht frei.csv\n",
      "smart_hans_08022022_194222_8_279-310_08_gny_.csv\n",
      "smart_hans_08022022_183929_12_397-426_08_mgy_.csv\n",
      "smart_hans_08022022_172937_3_121-152_08_mgn_.csv\n",
      "smart_hans_08022022_180422_9_304-333_08_wkn_.csv\n",
      "smart_hans_07312022_184145_4_116-140_08_wky_.csv\n",
      "smart_hans_08022022_191134_12_403-433_08_mny_.csv\n",
      "smart_hans_07312022_182045_9_300-329_08_wny_.csv\n",
      "smart_hans_07312022_181833_13_426-456_08_wny_.csv\n",
      "smart_hans_07312022_185608_7_246-274_08_mny_.csv\n",
      "smart_hans_08022022_174507_8_278-310_08_wny_.csv\n",
      "smart_hans_08022022_211254_8_282-313_08_mgy_.csv\n",
      "smart_hans_07252022_154259_11_395-432_08_mgy_.csv\n",
      "smart_hans_08022022_190931_3_120-151_08_mny_Person_hat_bei_8_weggeschaut.csv\n",
      "smart_hans_08022022_194359_4_153-185_08_gny_.csv\n",
      "smart_hans_08022022_211601_5_185-216_08_mky_.csv\n",
      "smart_hans_07312022_174621_4_127-151_08_mny_.csv\n",
      "smart_hans_07312022_165851_12_402-433_08_mgy_.csv\n",
      "smart_hans_08022022_211349_12_409-439_08_mgy_.csv\n",
      "smart_hans_07312022_174309_11_335-358_08_mny_.csv\n",
      "smart_hans_08022022_205354_9_308-338_08_wnn_.csv\n",
      "smart_hans_08022022_205208_8_276-308_08_wnn_.csv\n",
      "smart_hans_08022022_194312_8_282-313_08_gny_.csv\n",
      "smart_hans_08022022_182558_12_401-431_08_wny_person_unsicher_mit_zahl_1_zu_frueh.csv\n",
      "smart_hans_07312022_164702_5_181-209_08_mgy_.csv\n",
      "smart_hans_07312022_184630_3_98-121_08_wky_.csv\n",
      "smart_hans_07312022_164319_11_363-393_08_mny_.csv\n",
      "smart_hans_08022022_211111_7_249-279_08_mny_.csv\n",
      "smart_hans_08022022_184636_4_154-185_08_mny_.csv\n",
      "smart_hans_08022022_183848_8_265-293_08_mgy_.csv\n",
      "smart_hans_08022022_190224_8_271-301_08_mny_.csv\n",
      "smart_hans_07312022_173653_6_204-232_08_mny_.csv\n",
      "smart_hans_08022022_163526_4_153-182_08_mny_.csv\n",
      "smart_hans_08022022_172853_7_248-278_08_mgn_.csv\n",
      "smart_hans_07312022_184452_9_309-339_08_mny_.csv\n",
      "smart_hans_08022022_175729_10_335-365_08_wky_.csv\n",
      "smart_hans_08022022_185231_3_120-150_08_mny_.csv\n",
      "smart_hans_08022022_185137_12_400-430_08_mny_.csv\n",
      "smart_hans_08022022_184324_13_418-449_08_mgy_person_unkonzentriert.csv\n",
      "smart_hans_07312022_162745_8_272-303_08_mgy_.csv\n",
      "smart_hans_08022022_192632_11_371-402_08_wny_person_merkt_an_dass_sie_nach_oben_sieht.csv\n",
      "smart_hans_08022022_183037_8_274-304_08_wny_.csv\n",
      "smart_hans_08022022_191440_5_179-209_08_mny_.csv\n",
      "smart_hans_08022022_192802_10_344-373_08_wny_.csv\n",
      "smart_hans_07312022_173235_9_310-341_08_mnn_.csv\n",
      "smart_hans_07312022_185426_5_146-169_08_wky_.csv\n",
      "smart_hans_08022022_185315_3_120-149_08_mny_.csv\n",
      "smart_hans_08022022_180223_11_370-400_08_wkn_.csv\n",
      "smart_hans_08022022_184727_6_214-245_08_mny_.csv\n",
      "smart_hans_08022022_211022_9_314-345_08_mgy_.csv\n",
      "smart_hans_07312022_161226_7_250-280_08_mgy_.csv\n",
      "smart_hans_08022022_175542_5_181-211_08_wky_.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/adi/Dokumente/code/smart_hans/Machine_learning/compare_multiple_multivariate.ipynb Zelle 1\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adi/Dokumente/code/smart_hans/Machine_learning/compare_multiple_multivariate.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m models_folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adi/Dokumente/code/smart_hans/Machine_learning/compare_multiple_multivariate.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plots_folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvis/plots\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/adi/Dokumente/code/smart_hans/Machine_learning/compare_multiple_multivariate.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m dl \u001b[39m=\u001b[39m dataloader(scenario\u001b[39m=\u001b[39;49m num_scenario, path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/home/adi/cloudy_adlu/smart_hans/AP2/Daten/headpose_opencv_pitch_roll_yaw_20220904\u001b[39;49m\u001b[39m\"\u001b[39;49m, nr_taps\u001b[39m=\u001b[39;49mnr_taps, move_window_by\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m10\u001b[39;49m, feature_list\u001b[39m=\u001b[39;49mfeatures_to_learn_with)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adi/Dokumente/code/smart_hans/Machine_learning/compare_multiple_multivariate.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df_n \u001b[39m=\u001b[39m dl\u001b[39m.\u001b[39mdf\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adi/Dokumente/code/smart_hans/Machine_learning/compare_multiple_multivariate.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m cols \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df_n\u001b[39m.\u001b[39mcolumns)\n",
      "File \u001b[0;32m~/Dokumente/code/smart_hans/Machine_learning/datenverarbeitung/broken_dataloader.py:62\u001b[0m, in \u001b[0;36mdataloader.__init__\u001b[0;34m(self, path, scenario, nr_taps, move_window_by, feature_list, frac)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumn_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m     36\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnosetip_y\u001b[39m\u001b[39m\"\u001b[39m:           \u001b[39m1\u001b[39m ,\n\u001b[1;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnosetip_x\u001b[39m\u001b[39m\"\u001b[39m:           \u001b[39m2\u001b[39m ,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39myaw\u001b[39m\u001b[39m\"\u001b[39m:                 \u001b[39m22\u001b[39m\n\u001b[1;32m     58\u001b[0m }\n\u001b[1;32m     60\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_col_names(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size)\n\u001b[0;32m---> 62\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_train_test(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfrac, seed \u001b[39m=\u001b[39;49m \u001b[39m420\u001b[39;49m)\n",
      "File \u001b[0;32m~/Dokumente/code/smart_hans/Machine_learning/datenverarbeitung/broken_dataloader.py:94\u001b[0m, in \u001b[0;36mdataloader.get_train_test\u001b[0;34m(self, frac, seed)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 dataset_np \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_scenario_1_2(feature_arr_list, target_tap_nr, file, dataset_np)\n\u001b[1;32m     93\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscenario \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m                 dataset_np \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_scenario_3(feature_arr_list, target_tap_nr, file, dataset_np)\n\u001b[1;32m     96\u001b[0m \u001b[39m#            self.file_num = self.file_num + 1\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         dataset_df  \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(dataset_np[\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mtolist(), columns\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_names, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Dokumente/code/smart_hans/Machine_learning/datenverarbeitung/broken_dataloader.py:188\u001b[0m, in \u001b[0;36mdataloader.get_scenario_3\u001b[0;34m(self, feature_arr_list, target_tap_nr, file, dataset_np)\u001b[0m\n\u001b[1;32m    184\u001b[0m             window_list\u001b[39m.\u001b[39mappend(window_arr)\n\u001b[1;32m    187\u001b[0m         labeled_window \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_labeled_window(new_target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_num, k , window_list, file)\n\u001b[0;32m--> 188\u001b[0m         dataset_np \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_dataset(dataset_np, labeled_window)\n\u001b[1;32m    189\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_num \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_num \u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m dataset_np\n",
      "File \u001b[0;32m~/Dokumente/code/smart_hans/Machine_learning/datenverarbeitung/broken_dataloader.py:255\u001b[0m, in \u001b[0;36mdataloader.stack_dataset\u001b[0;34m(self, dataset_np, labeled_window)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack_dataset\u001b[39m(\u001b[39mself\u001b[39m, dataset_np, labeled_window):\n\u001b[1;32m    253\u001b[0m     \u001b[39m#check length of arr to make sure that files that are too short still can be used\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(labeled_window) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_names):\n\u001b[0;32m--> 255\u001b[0m         dataset_np \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack([dataset_np, labeled_window])\n\u001b[1;32m    256\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset_np\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda_torch_116/lib/python3.9/site-packages/numpy/core/shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tsai.all import *\n",
    "import pandas as pd\n",
    "from datenverarbeitung.broken_dataloader import dataloader\n",
    "from IPython.display import clear_output\n",
    "import datetime\n",
    "\n",
    "\n",
    "num_scenario = 3\n",
    "nr_taps = 2\n",
    "learning_cycles = 25\n",
    "features_to_learn_with = [\"pitch\",\"nosetip_y\",\"nosetip_x\",\"chin_x\",\"chin_y\",\"roll\",\"yaw\",\"left_eye_corner_x\",\"left_eye_corner_y\",\"right_eye_corner_x\",\"right_eye_corner_y\",\"left_mouth_corner_x\",\"left_mouth_corner_y\",\"right_mouth_corner_x\",\"right_mouth_corner_y\",\"nose_end_point_x\",\"nose_end_point_y\",\"head_pose1_x\",\"head_pose1_y\",\"head_pose2_x\",\"head_pose2_y\"]\n",
    "feature_list_string = '_'.join(features_to_learn_with)\n",
    "models_folder = \"models\"\n",
    "plots_folder = \"vis/plots\"\n",
    "\n",
    "dl = dataloader(scenario= num_scenario, path=\"/home/adi/cloudy_adlu/smart_hans/AP2/Daten/headpose_opencv_pitch_roll_yaw_20220904\", nr_taps=nr_taps, move_window_by=-10, feature_list=features_to_learn_with)\n",
    "df_n = dl.df\n",
    "\n",
    "cols = list(df_n.columns)\n",
    "a, b = cols.index('sample_index'), cols.index('feature')\n",
    "cols[b], cols[a] = cols[a], cols[b]\n",
    "df_n = df_n[cols]\n",
    "print(df_n)\n",
    "df_n = df_n.sort_values(['feature','target'])#.reset_index(drop=True)\n",
    "\n",
    "print(df_n[\"feature\"])\n",
    "print(df_n['sample_index'])\n",
    "print(\" hhhhhhhh \")\n",
    "\n",
    "X, old_y, names = df2xy (df_n, sample_col='sample_index', feat_col='feature', target_col='target', data_cols=None, steps_in_rows=True, return_names=True)\n",
    "\n",
    "print(names)\n",
    "print(f\"shape ours {df_n.shape}\")\n",
    "\n",
    "print(\"our X\")\n",
    "print(X.shape)\n",
    "print(X)\n",
    "\n",
    "print(\"our y\")\n",
    "print(old_y)\n",
    "print(old_y.shape)\n",
    "\n",
    "y = np.empty(len(old_y))\n",
    "for i, elem in enumerate(old_y):\n",
    "    for number in elem:\n",
    "            remainder = int(number) % 10\n",
    "            y[i] = remainder\n",
    "print(y)\n",
    "print(y.shape)\n",
    "   \n",
    "splits = get_splits(y, valid_size=.2)\n",
    "\n",
    "tfms  = [None, TSRegression()]\n",
    "\n",
    "dsets = TSDatasets( X,y,  inplace=True, splits=splits, tfms=[None, TSClassification()])\n",
    "\n",
    "print(dsets)\n",
    "\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, num_workers=0, tfms=[None, TSClassification()], item_tfs=TSClassification())\n",
    "\n",
    "dls.show_batch(sharey=True)\n",
    "\n",
    "archs = [(FCN, {}), (ResNet, {}), (xresnet1d34, {}), (ResCNN, {}), \n",
    "        (LSTM, {'n_layers':1, 'bidirectional': False}), (LSTM, {'n_layers':2, 'bidirectional': False}), (LSTM, {'n_layers':3, 'bidirectional': False}), \n",
    "        (LSTM, {'n_layers':1, 'bidirectional': True}), (LSTM, {'n_layers':2, 'bidirectional': True}), (LSTM, {'n_layers':3, 'bidirectional': True}),\n",
    "        (LSTM_FCN, {}), (LSTM_FCN, {'shuffle': False}), (InceptionTime, {}), (XceptionTime, {}), (OmniScaleCNN, {}), (mWDN, {'levels': 4})]\n",
    "\n",
    "results = pd.DataFrame(columns=['arch', 'hyperparams',  'train loss', 'valid loss', 'accuracy', 'time'])\n",
    "for i, (arch, k) in enumerate(archs):\n",
    "\n",
    "    save_name = \"multivariate_scenario_{}_{}_features_{}\".format(num_scenario, arch.__name__,\"features: \"+str(len(features_to_learn_with)))\n",
    "    ## set parameters for modelsaves\n",
    "    scenario_name_stage0 = save_name+\"_nr_taps_{}\".format(str(nr_taps))+\"_stage0\"\n",
    "\n",
    "    model = create_model(arch, dls=dls, **k)\n",
    "    print(model.__class__.__name__)\n",
    "    learn = Learner(dls, model,  metrics=accuracy)\n",
    "\n",
    "    learn.save(scenario_name_stage0)\n",
    "    learn.load(scenario_name_stage0)\n",
    "    learn.lr_find()\n",
    "    scenario_name_stage1 = scenario_name_stage0.replace(\"0\",\"1\")\n",
    "\n",
    "    start = time.time()\n",
    "    learn.fit_one_cycle(learning_cycles, 1e-3)\n",
    "    elapsed = time.time() - start\n",
    "    vals = learn.recorder.values[-1]\n",
    "    results.loc[i] = [arch.__name__, k, vals[0], vals[1], vals[2], int(elapsed)]\n",
    "    results.sort_values(by='accuracy', ascending=False, ignore_index=True, inplace=True)\n",
    "    \n",
    "    learn.plot_confusion_matrix()\n",
    "    current_time= datetime.datetime.now().strftime('%d%m%Y_%H%M%S')\n",
    "    plot_name = plots_folder+\"/confusion_matrix_\"+save_name+\"_nrtaps_{}_features_{}_learning_cycles_{}_{}.png\".format(str(nr_taps),feature_list_string,learning_cycles, current_time)\n",
    "    plt.savefig(plot_name, ext='png', bbox_inches=\"tight\")\n",
    "    clear_output(wait=True)\n",
    "    display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cuda_torch_116')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "728ae6c7abd908759bda430806e0e26c250d71ab8befc7fb4d37a0dcb830bff1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
